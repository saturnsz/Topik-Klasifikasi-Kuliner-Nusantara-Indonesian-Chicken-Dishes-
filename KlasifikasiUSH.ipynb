{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1p3NTItnp75uJPmDeCR35P3Wz51Nz_FKb",
      "authorship_tag": "ABX9TyMzTIt4JG2j4eL0+KrF1his",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/saturnsz/Topik-Klasifikasi-Kuliner-Nusantara-Indonesian-Chicken-Dishes-/blob/main/KlasifikasiUSH.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zELmoGgmIMPf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import glob\n",
        "import numpy as np\n",
        "import cv2"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pemuatan Data**"
      ],
      "metadata": {
        "id": "bOi5f1F05duM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "TRAIN_DIR = '/content/drive/MyDrive/train/train'\n",
        "TEST_DIR = '/content/drive/MyDrive/test/test'\n",
        "MIN_RESOLUTION = (50, 50) # Resolusi minimum (Lebar x Tinggi)\n",
        "\n",
        "# List untuk menampung data yang akan diproses selanjutnya\n",
        "train_image_paths = []\n",
        "train_image_labels = []\n",
        "test_image_paths = []\n",
        "class_names = []"
      ],
      "metadata": {
        "id": "V-Tc1qLVN1tB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def load_and_clean_data(data_dir, is_train_set=True):\n",
        "    \"\"\"\n",
        "    Memuat path gambar, label, dan membersihkan gambar rusak/low-res secara eksplisit.\n",
        "    \"\"\"\n",
        "    paths_list = []\n",
        "    labels_list = []\n",
        "    current_class_names = []\n",
        "    corrupted_count = 0\n",
        "    low_res_count = 0\n",
        "\n",
        "    print(f\"\\n--- Memproses Direktori: {data_dir} (Set: {'Train' if is_train_set else 'Test'}) ---\")\n",
        "\n",
        "    # Tentukan subfolder yang akan diiterasi\n",
        "    if is_train_set:\n",
        "        subfolders = [d for d in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, d))]\n",
        "    else:\n",
        "        # Untuk data test, kita asumsikan semua gambar ada di folder 'test' itu sendiri\n",
        "        # atau di subfolder, tergantung bagaimana data test Anda disiapkan.\n",
        "        # Kita akan iterasi di folder test saja untuk saat ini, jika test tidak berlabel.\n",
        "        subfolders = [''] # Folder root test\n",
        "\n",
        "    for subfolder_name in subfolders:\n",
        "        class_name = subfolder_name if is_train_set else 'unknown' # Hanya train yang punya label\n",
        "\n",
        "        if is_train_set:\n",
        "            current_class_names.append(class_name)\n",
        "\n",
        "        folder_path = os.path.join(data_dir, subfolder_name)\n",
        "\n",
        "        # Cari semua file .jpg di dalam folder\n",
        "        files = glob.glob(os.path.join(folder_path, '*.jpg'))\n",
        "\n",
        "        for file_path in files:\n",
        "\n",
        "            # 1. Pemeriksaan Gambar Rusak (cv2.imread)\n",
        "            img = cv2.imread(file_path)\n",
        "\n",
        "            if img is None:\n",
        "                corrupted_count += 1\n",
        "                # print(f\"  [Dihapus] Rusak: {file_path}\")\n",
        "                continue\n",
        "\n",
        "            # 2. Pemeriksaan Outlier Resolusi Rendah\n",
        "            height, width, _ = img.shape\n",
        "\n",
        "            if width < MIN_RESOLUTION[0] or height < MIN_RESOLUTION[1]:\n",
        "                low_res_count += 1\n",
        "                # print(f\"  [Dihapus] Low Res ({width}x{height}): {file_path}\")\n",
        "                continue\n",
        "\n",
        "            # Jika lolos validasi\n",
        "            paths_list.append(file_path)\n",
        "            if is_train_set:\n",
        "                labels_list.append(class_name)\n",
        "\n",
        "    print(f\"Total Sampel Awal Dihapus karena Rusak: {corrupted_count}\")\n",
        "    print(f\"Total Sampel Awal Dihapus karena Low-Res: {low_res_count}\")\n",
        "\n",
        "    if is_train_set:\n",
        "        return np.array(paths_list), np.array(labels_list), current_class_names\n",
        "    else:\n",
        "        return np.array(paths_list), None, None"
      ],
      "metadata": {
        "id": "seRrj_nmOB13"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# A. Muat dan Bersihkan Data TRAIN\n",
        "train_image_paths, train_image_labels, class_names = load_and_clean_data(TRAIN_DIR, is_train_set=True)\n",
        "\n",
        "# B. Muat dan Bersihkan Data TEST\n",
        "test_image_paths, _, _ = load_and_clean_data(TEST_DIR, is_train_set=False)\n",
        "\n",
        "print(\"\\n--- Ringkasan Hasil Tahap 1 ---\")\n",
        "print(f\"1. Kelas yang Ditemukan: {class_names}\")\n",
        "print(f\"2. Total Gambar Latih Bersih: {len(train_image_paths)}\")\n",
        "print(f\"3. Total Gambar Uji Bersih: {len(test_image_paths)}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LYRfKOWiODx_",
        "outputId": "2ff487c0-b7b3-44c7-b437-5e64922c9395"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Memproses Direktori: /content/drive/MyDrive/train/train (Set: Train) ---\n",
            "Total Sampel Awal Dihapus karena Rusak: 0\n",
            "Total Sampel Awal Dihapus karena Low-Res: 0\n",
            "\n",
            "--- Memproses Direktori: /content/drive/MyDrive/test/test (Set: Test) ---\n",
            "Total Sampel Awal Dihapus karena Rusak: 0\n",
            "Total Sampel Awal Dihapus karena Low-Res: 0\n",
            "\n",
            "--- Ringkasan Hasil Tahap 1 ---\n",
            "1. Kelas yang Ditemukan: ['Ayam Pop', 'Ayam Betutu', 'Ayam Goreng', 'Ayam Bakar']\n",
            "2. Total Gambar Latih Bersih: 1086\n",
            "3. Total Gambar Uji Bersih: 269\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pra-pemrosesan Data (Preprocessing)**"
      ],
      "metadata": {
        "id": "OpumCaA35jDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "import tensorflow as tf\n",
        "\n",
        "# 1. Encoding Label Teks ke Numerik\n",
        "le = LabelEncoder()\n",
        "train_labels_encoded = le.fit_transform(train_image_labels)\n",
        "# print(f\"Label Mapping: {dict(zip(le.classes_, le.transform(le.classes_))}\")\n",
        "\n",
        "# 2. Pembagian Data Train menjadi Train dan Validation (80:20)\n",
        "# Stratify=True memastikan pembagian proporsi kelas yang merata\n",
        "X_train_paths, X_val_paths, y_train_labels, y_val_labels = train_test_split(\n",
        "    train_image_paths,\n",
        "    train_labels_encoded,\n",
        "    test_size=0.2, # 20% untuk Validasi\n",
        "    random_state=42,\n",
        "    shuffle=True,\n",
        "    stratify=train_labels_encoded # Penting untuk menjaga keseimbangan kelas\n",
        ")\n",
        "\n",
        "# 3. Konversi label ke format One-Hot Encoding\n",
        "y_train_one_hot = tf.keras.utils.to_categorical(y_train_labels, num_classes=len(class_names))\n",
        "y_val_one_hot = tf.keras.utils.to_categorical(y_val_labels, num_classes=len(class_names))\n",
        "\n",
        "print(f\"\\n--- Pembagian Data (Stratified) ---\")\n",
        "print(f\"Gambar Pelatihan: {len(X_train_paths)} ({len(y_train_one_hot)} label)\")\n",
        "print(f\"Gambar Validasi: {len(X_val_paths)} ({len(y_val_one_hot)} label)\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PUcAEN7eOHGH",
        "outputId": "407ea068-9352-4739-8d1a-831142ee3d29"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Pembagian Data (Stratified) ---\n",
            "Gambar Pelatihan: 868 (868 label)\n",
            "Gambar Validasi: 218 (218 label)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoding Label\n",
        "Objektif: Mengubah label teks (misalnya, \"Ayam Bakar\", \"Ayam Pop\") menjadi nilai numerik unik (misalnya, 0, 1, 2, 3) menggunakan LabelEncoder.\n",
        "\n",
        "Pembagian Data Pelatihan dan Validasi (Stratified Split)\n",
        "Membagi dataset pelatihan (train_image_paths) menjadi dua bagian, 80% untuk Pelatihan dan 20% untuk Validasi, memastikan distribusi sampel untuk setiap kelas tetap seimbang (Stratified Split).\n",
        "\n",
        "Konversi ke One-Hot Encoding\n",
        "Mengubah label numerik (misalnya, 0) menjadi format vektor biner (One-Hot Encoding) yang diperlukan untuk fungsi loss Categorical Cross-Entropy dalam klasifikasi multi-kelas (misalnya, 0 menjadi [1, 0, 0, 0]).\n"
      ],
      "metadata": {
        "id": "U5yoWh3n58Zk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# parameter preprocessing\n",
        "IMAGE_SIZE = (224, 224)\n",
        "BATCH_SIZE = 32\n",
        "# NUM_CLASSES sudah ditentukan sebelumnya\n",
        "\n",
        "def load_and_preprocess_image(path, label=None, augment=False):\n",
        "    \"\"\"Fungsi untuk memuat gambar, mengubah ukuran, dan normalisasi.\"\"\"\n",
        "\n",
        "    # Pra-pemrosesan Inti\n",
        "    # 1. Muat Gambar (TensorFlow way)\n",
        "    img = tf.io.read_file(path)\n",
        "    img = tf.image.decode_jpeg(img, channels=3)\n",
        "\n",
        "    # 2. Ubah Ukuran\n",
        "    img = tf.image.resize(img, IMAGE_SIZE) # (224, 224)\n",
        "\n",
        "    # 3. Normalisasi\n",
        "    img = img / 255.0\n",
        "\n",
        "    # 4. Augmentasi (Eksplisit Feature Engineering)\n",
        "    if augment:\n",
        "\n",
        "        # Rotasi dan Zoom seringkali rumit jika langsung diimplementasikan\n",
        "        # menggunakan fungsi dasar tf.image dalam tf.data.\n",
        "        # Kita akan menggunakan Augmentasi sederhana yang pasti didukung:\n",
        "\n",
        "        # Horizontal Flip\n",
        "        img = tf.image.random_flip_left_right(img)\n",
        "\n",
        "\n",
        "        # Penyesuaian Kecerahan/Kontras Acak\n",
        "        img = tf.image.random_brightness(img, max_delta=0.1) # Sesuaikan kecerahan\n",
        "        img = tf.image.random_contrast(img, lower=0.9, upper=1.1) # Sesuaikan kontras\n",
        "\n",
        "    if label is not None:\n",
        "        return img, label\n",
        "    return img\n",
        "\n",
        "# Pembentukan Pipeline\n",
        "# Membuat TF Datasets\n",
        "train_ds = tf.data.Dataset.from_tensor_slices((X_train_paths, y_train_one_hot))\n",
        "train_ds = train_ds.map(lambda x, y: load_and_preprocess_image(x, y, augment=True),\n",
        "                        num_parallel_calls=tf.data.AUTOTUNE)\n",
        "train_ds = train_ds.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "val_ds = tf.data.Dataset.from_tensor_slices((X_val_paths, y_val_one_hot))\n",
        "val_ds = val_ds.map(lambda x, y: load_and_preprocess_image(x, y, augment=False),\n",
        "                    num_parallel_calls=tf.data.AUTOTUNE)\n",
        "val_ds = val_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(\"\\nDataset Latih dan Validasi Kustom siap untuk pelatihan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ga1MVGWPiZO",
        "outputId": "a6ff8100-8d3a-44a5-da02-a8b166e36e85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Dataset Latih dan Validasi Kustom siap untuk pelatihan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Pembentukan Model MobileNetV2**"
      ],
      "metadata": {
        "id": "FI3V3g737WYi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fase 1\n",
        "from tensorflow.keras.applications import MobileNetV2\n",
        "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "# Model Configuration\n",
        "BASE_MODEL_TRAINABLE_LAYERS = 0 # Mulai dengan membekukan semua lapisan Base Model\n",
        "\n",
        "# 1. Muat Base Model\n",
        "base_model = MobileNetV2(\n",
        "    input_shape=(IMAGE_SIZE[0], IMAGE_SIZE[1], 3),\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "\n",
        "# 2. Atur Lapisan Trainable\n",
        "base_model.trainable = (BASE_MODEL_TRAINABLE_LAYERS > 0)\n",
        "\n",
        "# 3. Tambahkan Lapisan Klasifikasi (Custom Head)\n",
        "x = base_model.output\n",
        "x = GlobalAveragePooling2D()(x)\n",
        "x = Dense(512, activation='relu')(x)\n",
        "x = Dropout(0.5)(x) # Regulasi Eksplisit (Corrected: apply dropout to x)\n",
        "predictions = Dense(NUM_CLASSES, activation='softmax')(x)\n",
        "\n",
        "model = Model(inputs=base_model.input, outputs=predictions)\n",
        "\n",
        "# 4. Compile Model (Fase 1: Melatih Custom Head Saja)\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# Callbacks Eksplisit\n",
        "checkpoint_filepath = 'best_model.weights.h5' # Corrected filepath\n",
        "model_checkpoint_callback = ModelCheckpoint(\n",
        "    filepath=checkpoint_filepath,\n",
        "    save_weights_only=True,\n",
        "    monitor='val_accuracy',\n",
        "    mode='max',\n",
        "    save_best_only=True\n",
        ")\n",
        "\n",
        "early_stopping_callback = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    patience=5, # 5 epochs tanpa perbaikan\n",
        "    restore_best_weights=True\n",
        ")\n",
        "\n",
        "print(\"\\nModel siap. Akan memulai Fase 1: Pelatihan Custom Head.\")\n",
        "\n",
        "# 5. Pelatihan Model (Fase 1: Training Custom Head)\n",
        "# Pelatihan harus disesuaikan dengan kebutuhan Anda\n",
        "history_phase_1 = model.fit(\n",
        "    train_ds,\n",
        "    epochs=10, # Misalnya 10 epochs\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[model_checkpoint_callback, early_stopping_callback]\n",
        ")\n",
        "\n",
        "print(\"\\nPelatihan Fase 1 Selesai. Hasil Bobot Terbaik Disimpan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MQEHy4NTPojG",
        "outputId": "4a9f074b-c7fc-4801-a4f2-eadade53998f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model siap. Akan memulai Fase 1: Pelatihan Custom Head.\n",
            "Epoch 1/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 2s/step - accuracy: 0.4839 - loss: 1.4085 - val_accuracy: 0.6972 - val_loss: 0.7270\n",
            "Epoch 2/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 2s/step - accuracy: 0.7287 - loss: 0.6776 - val_accuracy: 0.7477 - val_loss: 0.6234\n",
            "Epoch 3/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m78s\u001b[0m 1s/step - accuracy: 0.7728 - loss: 0.5533 - val_accuracy: 0.7890 - val_loss: 0.5949\n",
            "Epoch 4/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 2s/step - accuracy: 0.8214 - loss: 0.4502 - val_accuracy: 0.8073 - val_loss: 0.5528\n",
            "Epoch 5/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 1s/step - accuracy: 0.8413 - loss: 0.3930 - val_accuracy: 0.7523 - val_loss: 0.7504\n",
            "Epoch 6/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 1s/step - accuracy: 0.8571 - loss: 0.3666 - val_accuracy: 0.7982 - val_loss: 0.5637\n",
            "Epoch 7/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 1s/step - accuracy: 0.9102 - loss: 0.2776 - val_accuracy: 0.7936 - val_loss: 0.6024\n",
            "Epoch 8/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 1s/step - accuracy: 0.9078 - loss: 0.2429 - val_accuracy: 0.7569 - val_loss: 0.6340\n",
            "Epoch 9/10\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 1s/step - accuracy: 0.9197 - loss: 0.2275 - val_accuracy: 0.7523 - val_loss: 0.6743\n",
            "\n",
            "Pelatihan Fase 1 Selesai. Hasil Bobot Terbaik Disimpan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Fine-Tuning Eksplisit**"
      ],
      "metadata": {
        "id": "-P_klvRU7nKh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "meningkatkan performa model secara substansial"
      ],
      "metadata": {
        "id": "-m7vnnz8ICJ4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Fase 2\n",
        "# 1. Buka blokir Base Model (Fine-Tuning)\n",
        "base_model.trainable = True\n",
        "\n",
        "# 2. Bekukan lapisan awal yang berisi fitur umum\n",
        "# Umumnya, kita membekukan sekitar 50-70% dari lapisan awal\n",
        "# Misalnya, MobileNetV2 punya banyak lapisan, kita akan membekukan lapisan awal\n",
        "# Kita akan unfreeze 50 lapisan terakhir\n",
        "fine_tune_at = len(base_model.layers) - 50 # Misalnya 50 lapisan terakhir\n",
        "\n",
        "for layer in base_model.layers[:fine_tune_at]:\n",
        "    layer.trainable = False\n",
        "\n",
        "# 3. Compile Ulang Model dengan Learning Rate yang Lebih Kecil\n",
        "# Learning Rate yang kecil mencegah bobot pre-trained rusak terlalu cepat\n",
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5), # Sangat kecil!\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "print(f\"\\nModel siap. Akan memulai Fase 2: Fine-Tuning pada {len(model.trainable_variables)} variabel yang dapat dilatih.\")\n",
        "\n",
        "# 4. Pelatihan Model (Fase 2: Fine-Tuning)\n",
        "# Lanjutkan pelatihan dari bobot terbaik sebelumnya\n",
        "history_phase_2 = model.fit(\n",
        "    train_ds,\n",
        "    epochs=20, # Lanjutkan selama 10-20 epochs lagi\n",
        "    initial_epoch=history_phase_1.epoch[-1], # Mulai dari epoch terakhir Fase 1\n",
        "    validation_data=val_ds,\n",
        "    callbacks=[model_checkpoint_callback, early_stopping_callback]\n",
        ")\n",
        "\n",
        "print(\"\\nPelatihan Fine-Tuning Selesai. Bobot terbaik telah digunakan.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yEMAjwxFSc1b",
        "outputId": "f964436f-4cab-4482-b064-a0606aac79af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Model siap. Akan memulai Fase 2: Fine-Tuning pada 55 variabel yang dapat dilatih.\n",
            "Epoch 9/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m98s\u001b[0m 2s/step - accuracy: 0.6622 - loss: 0.8728 - val_accuracy: 0.7615 - val_loss: 0.6077\n",
            "Epoch 10/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 2s/step - accuracy: 0.7453 - loss: 0.6497 - val_accuracy: 0.7477 - val_loss: 0.6681\n",
            "Epoch 11/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m83s\u001b[0m 2s/step - accuracy: 0.7975 - loss: 0.5372 - val_accuracy: 0.7339 - val_loss: 0.7164\n",
            "Epoch 12/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 2s/step - accuracy: 0.8112 - loss: 0.4724 - val_accuracy: 0.7156 - val_loss: 0.7520\n",
            "Epoch 13/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.8296 - loss: 0.4579 - val_accuracy: 0.7110 - val_loss: 0.7860\n",
            "Epoch 14/20\n",
            "\u001b[1m28/28\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 2s/step - accuracy: 0.8507 - loss: 0.4220 - val_accuracy: 0.7110 - val_loss: 0.7973\n",
            "\n",
            "Pelatihan Fine-Tuning Selesai. Bobot terbaik telah digunakan.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Tahap Pembentukan Dataset Pengujian**"
      ],
      "metadata": {
        "id": "-GldzvOp9shK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "memastikan data dimuat dan dipra-proses secara konsisten dan efisien"
      ],
      "metadata": {
        "id": "MGLrtged9zQK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "# Pastikan model (Model) dan IMAGE_SIZE sudah didefinisikan dari langkah sebelumnya\n",
        "\n",
        "# --- 1. Persiapan Data Test ---\n",
        "# Buat TF Dataset dari path gambar test\n",
        "# Kita hanya perlu path, karena tidak ada label (y=None)\n",
        "test_ds = tf.data.Dataset.from_tensor_slices(test_image_paths) # Inisialisasi Dataset dari Paths\n",
        "\n",
        "\n",
        "# Terapkan fungsi preprocessing tanpa augmentasi\n",
        "# Fungsi load_and_preprocess_image harus mampu menangani label None\n",
        "# load_and_preprocess_image(path, label=None, augment=False)\n",
        "# Menerapkan langkah-langkah resize dan Normalisasi\n",
        "test_ds = test_ds.map(lambda x: load_and_preprocess_image(x, augment=False),\n",
        "                      num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "# Batching dataset\n",
        "# Shuffle=False penting untuk menjaga urutan prediksi\n",
        "test_ds = test_ds.batch(BATCH_SIZE).prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "print(f\"Dataset Pengujian siap dengan {len(test_image_paths)} sampel.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2LkmKCFQWAjZ",
        "outputId": "489e7b37-9686-402d-822c-58640416f7ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset Pengujian siap dengan 269 sampel.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inferensi (Inference)**"
      ],
      "metadata": {
        "id": "QlWu6hdH_caK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Asumsikan Anda telah mendefinisikan arsitektur model (model) seperti di langkah sebelumnya\n",
        "# dan bobot terbaik disimpan di 'best_model.h5'\n",
        "try:\n",
        "    # Memuat bobot terbaik yang disimpan oleh ModelCheckpoint\n",
        "    model.load_weights(checkpoint_filepath)\n",
        "    print(\"Bobot terbaik telah berhasil dimuat kembali dari checkpoint.\")\n",
        "except Exception as e:\n",
        "    print(f\"Gagal memuat bobot model. Menggunakan bobot saat ini. Error: {e}\")\n",
        "\n",
        "# --- 3. Prediksi ---\n",
        "\n",
        "print(\"Membuat prediksi pada set Pengujian...\")\n",
        "# Melakukan prediksi pada seluruh dataset test\n",
        "predictions = model.predict(test_ds)\n",
        "\n",
        "# Mengkonversi hasil prediksi (probabilitas Softmax) menjadi label kelas (indeks)\n",
        "# np.argmax mengambil indeks probabilitas tertinggi\n",
        "predicted_labels_index = np.argmax(predictions, axis=1)\n",
        "\n",
        "# Mengkonversi indeks kelas menjadi nama kelas (teks)\n",
        "# Gunakan le.classes_ (dari LabelEncoder yang digunakan di langkah sebelumnya)\n",
        "predicted_class_names = le.inverse_transform(predicted_labels_index)\n",
        "\n",
        "print(\"\\nPrediksi selesai.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s9-FzTE6WC9J",
        "outputId": "4ea001b2-63d1-4455-9cc5-16c2d17d2aeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/keras/src/saving/saving_lib.py:802: UserWarning: Skipping variable loading for optimizer 'adam', because it has 112 variables whereas the saved optimizer has 10 variables. \n",
            "  saveable.load_own_variables(weights_store.get(inner_path))\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bobot terbaik telah berhasil dimuat kembali dari checkpoint.\n",
            "Membuat prediksi pada set Pengujian...\n",
            "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 1s/step\n",
            "\n",
            "Prediksi selesai.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_true = y_val_labels\n",
        "predictions_val = model.predict(val_ds)\n",
        "predicted_val_labels_index = np.argmax(predictions_val, axis=1)\n",
        "\n",
        "print(\"\\n--- 4. Laporan Klasifikasi (Hanya Ilustrasi/Validasi) ---\")\n",
        "print(classification_report(y_true, predicted_val_labels_index, target_names=class_names))\n",
        "\n",
        "print(\"\\n--- Matriks Kebingungan ---\")\n",
        "cm = confusion_matrix(y_true, predicted_val_labels_index)\n",
        "print(cm)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4yaU0FRrWO0Q",
        "outputId": "70485e53-fb2b-47cd-aca1-857af6d5646a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m7/7\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 2s/step\n",
            "\n",
            "--- 4. Laporan Klasifikasi (Hanya Ilustrasi/Validasi) ---\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    Ayam Pop       0.81      0.77      0.79        56\n",
            " Ayam Betutu       0.81      0.83      0.82        46\n",
            " Ayam Goreng       0.73      0.82      0.77        65\n",
            "  Ayam Bakar       0.93      0.82      0.88        51\n",
            "\n",
            "    accuracy                           0.81       218\n",
            "   macro avg       0.82      0.81      0.81       218\n",
            "weighted avg       0.81      0.81      0.81       218\n",
            "\n",
            "\n",
            "--- Matriks Kebingungan ---\n",
            "[[43  3  9  1]\n",
            " [ 1 38  7  0]\n",
            " [ 6  4 53  2]\n",
            " [ 3  2  4 42]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "submission_df = pd.DataFrame({\n",
        "    'file_path': test_image_paths, # Atau hanya nama file saja\n",
        "    'predicted_class': predicted_class_names\n",
        "})\n",
        "\n",
        "# Anda mungkin perlu menyesuaikan kolom ini sesuai dengan format yang diminta\n",
        "submission_df['filename'] = submission_df['file_path'].apply(lambda x: os.path.basename(x))\n",
        "final_submission_df = submission_df[['filename', 'predicted_class']]\n",
        "\n",
        "# Simpan ke file CSV\n",
        "submission_filename = 'submission_ayam_nusantara.csv'\n",
        "final_submission_df.to_csv(submission_filename, index=False)\n",
        "\n",
        "print(f\"\\nFile submission berhasil dibuat: {submission_filename}\")\n",
        "print(\"Contoh 5 baris pertama hasil prediksi:\")\n",
        "print(final_submission_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YQh7nYftWXoA",
        "outputId": "dff64794-e664-419f-c451-03b781aadeab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "File submission berhasil dibuat: submission_ayam_nusantara.csv\n",
            "Contoh 5 baris pertama hasil prediksi:\n",
            "  filename predicted_class\n",
            "0  185.jpg     Ayam Goreng\n",
            "1  026.jpg        Ayam Pop\n",
            "2  012.jpg     Ayam Goreng\n",
            "3  239.jpg        Ayam Pop\n",
            "4  075.jpg      Ayam Bakar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# 1. Muat file submission Anda\n",
        "df_submission = pd.read_csv(\"/content/drive/MyDrive/submission_ayam_nusantara.csv\")\n",
        "\n",
        "# 2. Periksa kolom yang ada\n",
        "print(\"Kolom asli:\", df_submission.columns.tolist())\n",
        "\n",
        "# 3. Ganti nama kolom agar sesuai dengan format yang diminta\n",
        "# Menggunakan asumsi format yang diminta adalah 'Id' dan 'label'\n",
        "df_submission.rename(columns={\n",
        "    'filename': 'Id',\n",
        "    'predicted_class': 'label'\n",
        "}, inplace=True)\n",
        "\n",
        "# 4. Pastikan hanya dua kolom yang ada dan urutannya benar\n",
        "df_final_submission = df_submission[['Id', 'label']]\n",
        "\n",
        "# 5. Simpan file baru\n",
        "fixed_submission_filename = 'fixed_final_submission.csv'\n",
        "df_final_submission.to_csv(fixed_submission_filename, index=False)\n",
        "\n",
        "print(f\"\\nFile submission baru (fixed) berhasil dibuat: {fixed_submission_filename}\")\n",
        "print(\"Pastikan untuk mengunggah file ini!\")\n",
        "print(\"\\n5 baris pertama file baru:\")\n",
        "print(df_final_submission.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VZp2GjxWyj_D",
        "outputId": "edf6a646-3428-4cb4-cfc4-2f833a92f5d3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Kolom asli: ['filename', 'predicted_class']\n",
            "\n",
            "File submission baru (fixed) berhasil dibuat: fixed_final_submission.csv\n",
            "Pastikan untuk mengunggah file ini!\n",
            "\n",
            "5 baris pertama file baru:\n",
            "        Id        label\n",
            "0  185.jpg  Ayam Goreng\n",
            "1  026.jpg     Ayam Pop\n",
            "2  012.jpg  Ayam Goreng\n",
            "3  239.jpg     Ayam Pop\n",
            "4  075.jpg   Ayam Bakar\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "filename = \"/content/fixed_final_submission.csv\"\n",
        "\n",
        "try:\n",
        "    df_submission = pd.read_csv(filename)\n",
        "\n",
        "    print(f\"Menampilkan Isi File: {filename}\")\n",
        "\n",
        "    # 1. Tampilkan informasi dasar (jumlah baris/kolom)\n",
        "    print(\"\\n[Informasi Struktur Data]\")\n",
        "    df_submission.info()\n",
        "\n",
        "    # 2. Tampilkan 10 baris pertama\n",
        "    print(\"\\n[10 Baris Pertama (Header dan Data)]\")\n",
        "    print(df_submission.head(10))\n",
        "\n",
        "    # 3. Tampilkan 5 baris terakhir\n",
        "    print(\"\\n[5 Baris Terakhir]\")\n",
        "    print(df_submission.tail())\n",
        "\n",
        "    # 4. Verifikasi nilai unik (opsional, untuk memastikan label kelas benar)\n",
        "    print(\"\\n[Verifikasi Label Kelas Unik]\")\n",
        "    print(df_submission['label'].value_counts())\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(f\"ERROR: File '{filename}' tidak ditemukan. Pastikan file berada di direktori yang sama.\")\n",
        "except Exception as e:\n",
        "    print(f\"Terjadi error saat memuat data: {e}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xuhURyCBBJvJ",
        "outputId": "ebeb80c7-1b1f-4e14-de79-53e2bc61c63b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Menampilkan Isi File: /content/fixed_final_submission.csv\n",
            "\n",
            "[Informasi Struktur Data]\n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 269 entries, 0 to 268\n",
            "Data columns (total 2 columns):\n",
            " #   Column  Non-Null Count  Dtype \n",
            "---  ------  --------------  ----- \n",
            " 0   Id      269 non-null    object\n",
            " 1   label   269 non-null    object\n",
            "dtypes: object(2)\n",
            "memory usage: 4.3+ KB\n",
            "\n",
            "[10 Baris Pertama (Header dan Data)]\n",
            "        Id        label\n",
            "0  185.jpg  Ayam Goreng\n",
            "1  026.jpg     Ayam Pop\n",
            "2  012.jpg  Ayam Goreng\n",
            "3  239.jpg     Ayam Pop\n",
            "4  075.jpg   Ayam Bakar\n",
            "5  010.jpg   Ayam Bakar\n",
            "6  147.jpg   Ayam Bakar\n",
            "7  210.jpg     Ayam Pop\n",
            "8  006.jpg  Ayam Goreng\n",
            "9  234.jpg  Ayam Goreng\n",
            "\n",
            "[5 Baris Terakhir]\n",
            "          Id        label\n",
            "264  125.jpg  Ayam Goreng\n",
            "265  250.jpg  Ayam Goreng\n",
            "266  259.jpg  Ayam Betutu\n",
            "267  123.jpg  Ayam Goreng\n",
            "268  182.jpg     Ayam Pop\n",
            "\n",
            "[Verifikasi Label Kelas Unik]\n",
            "label\n",
            "Ayam Goreng    126\n",
            "Ayam Bakar      61\n",
            "Ayam Pop        42\n",
            "Ayam Betutu     40\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    }
  ]
}